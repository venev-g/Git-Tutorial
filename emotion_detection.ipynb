{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J6eWqz3aM4d",
        "outputId": "bf86ef03-8595-417e-9028-79dfea041cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'emotion-recognition-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/emotion-recognition-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sujaykapadnis/emotion-recognition-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /kaggle/input/emotion-recognition-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVdO7VNQacTY",
        "outputId": "3ceb5e2d-c589-45cd-f4b4-0fe785afe18e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.csv  \u001b[0m\u001b[01;34mdataset\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /kaggle/input/emotion-recognition-dataset/dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur6dyCXsbqsv",
        "outputId": "4bca4b07-d7af-40da-90d6-0f3b6f66a1d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mAhegao\u001b[0m/  \u001b[01;34mAngry\u001b[0m/  \u001b[01;34mHappy\u001b[0m/  \u001b[01;34mNeutral\u001b[0m/  \u001b[01;34mSad\u001b[0m/  \u001b[01;34mSurprise\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "3lNlplT0cFb7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "Rbt-CxNTc01k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_dir = \"/kaggle/input/emotion-recognition-dataset/dataset/\"\n",
        "train_dir = 'dataset_split/train'\n",
        "val_dir = 'dataset_split/val'"
      ],
      "metadata": {
        "id": "MbctmrfMc21I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = .1\n",
        "\n",
        "os.makedirs(train_dir,exist_ok=True)\n",
        "os.makedirs(val_dir,exist_ok=True)"
      ],
      "metadata": {
        "id": "AfzUph0XfAsh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in os.listdir(original_dir):\n",
        "  cpath = os.path.join(original_dir,c)\n",
        "  print(cpath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGUcMWQDgSHD",
        "outputId": "61fcdcfb-3bd0-45a5-b03d-fba9bf7f7354"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/emotion-recognition-dataset/dataset/Surprise\n",
            "/kaggle/input/emotion-recognition-dataset/dataset/Angry\n",
            "/kaggle/input/emotion-recognition-dataset/dataset/Neutral\n",
            "/kaggle/input/emotion-recognition-dataset/dataset/Sad\n",
            "/kaggle/input/emotion-recognition-dataset/dataset/Happy\n",
            "/kaggle/input/emotion-recognition-dataset/dataset/Ahegao\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in os.listdir(original_dir):\n",
        "    class_path = os.path.join(original_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(class_path)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_index = int(len(images) * split_ratio)\n",
        "    val_images = images[:split_index]\n",
        "    train_images = images[split_index:]\n",
        "\n",
        "    # Create subfolders for each class\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "ivPGmAX1fOPz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "# Make train and val directories\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(original_dir):\n",
        "    class_path = os.path.join(original_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(class_path)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_index = int(len(images) * split_ratio)\n",
        "    val_images = images[:split_index]\n",
        "    train_images = images[split_index:]\n",
        "\n",
        "    # Create subfolders for each class\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "    for img in train_images:\n",
        "        src = os.path.join(class_path, img)\n",
        "        dst = os.path.join(train_dir, class_name, img)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    for img in val_images:\n",
        "        src = os.path.join(class_path, img)\n",
        "        dst = os.path.join(val_dir, class_name, img)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    print(f\"{class_name}: {len(train_images)} training images, {len(val_images)} validation images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4CjBAq5g0w4",
        "outputId": "54eb05a5-afd7-4954-f45a-a81e2c089e81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Surprise: 1111 training images, 123 validation images\n",
            "Angry: 1182 training images, 131 validation images\n",
            "Neutral: 3625 training images, 402 validation images\n",
            "Sad: 3541 training images, 393 validation images\n",
            "Happy: 3366 training images, 374 validation images\n",
            "Ahegao: 1085 training images, 120 validation images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "WL8VHdybmuMv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=90,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=.2)"
      ],
      "metadata": {
        "id": "rCxHxtAPpapM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "MAQ1d5UOrTgI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(271,271),\n",
        "                                                    batch_size=33,\n",
        "                                                    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_9u6IIgrcGI",
        "outputId": "8bf4866d-ba1f-4629-a29f-c7555e9035d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13910 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = val_datagen.flow_from_directory(val_dir,\n",
        "                                                    target_size=(271,271),\n",
        "                                                    batch_size=33,\n",
        "                                                    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0jL7hVqry8p",
        "outputId": "162b556e-bb72-4313-920a-c54613653114"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1543 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "jf7ZPH7atJcN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, 3, input_shape=(271, 271, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWF8dA6BtrRy",
        "outputId": "74fbadfe-4873-4832-cd8d-39eb8ded4a7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FzbeShrzuV4C"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit = model.fit(train_generator,\n",
        "                epochs=10,\n",
        "                validation_data=val_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnkTRvDwwElV",
        "outputId": "52e6b7c2-3111-49aa-e257-b19a3369994e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 746ms/step - accuracy: 0.2494 - loss: 1.7387 - val_accuracy: 0.2923 - val_loss: 1.6200\n",
            "Epoch 2/10\n",
            "\u001b[1m358/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m44s\u001b[0m 694ms/step - accuracy: 0.2957 - loss: 1.5819"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MeLsGhEMwTJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}